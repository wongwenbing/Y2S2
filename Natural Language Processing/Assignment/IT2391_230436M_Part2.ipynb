{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf86330-1d0e-4d43-8188-187610316e14",
   "metadata": {},
   "source": [
    "## **Text Feature Engineering and Modelling**\n",
    "Done by Wong Wen Bing 230436M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a4a8b6-5f8f-4738-8635-a1a3c0c20d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66650e8-efd8-474d-9ff0-1e2b03d0b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a740b91-33c0-4afd-b889-860b2bc174a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "423b828b-21ec-487c-955f-bc16282d2fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>species</th>\n",
       "      <th>text_length</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>chunked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2 Jun 2023 ï¿½ The Javan myna shares some simi...</td>\n",
       "      <td>Javan Myna</td>\n",
       "      <td>162</td>\n",
       "      <td>jun javan myna share similarity common myna te...</td>\n",
       "      <td>jun javan_myna share similarity common myna te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Click here for more information about the Red ...</td>\n",
       "      <td>Collared Kingfisher</td>\n",
       "      <td>398</td>\n",
       "      <td>click information red list category criterion ...</td>\n",
       "      <td>click information red list category criterion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The black-headed oriole ( Oriolus larvatus) is...</td>\n",
       "      <td>Black-naped Oriole</td>\n",
       "      <td>349</td>\n",
       "      <td>black headed oriole oriolus larvatus specie bi...</td>\n",
       "      <td>black_headed_oriole oriolus larvatus specie bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Search from thousands of royalty-free \"Javan M...</td>\n",
       "      <td>Javan Myna</td>\n",
       "      <td>177</td>\n",
       "      <td>search thousand royalty free javan myna stock ...</td>\n",
       "      <td>search thousand royalty free javan_myna stock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>521 foreground recordings and 156 background ...</td>\n",
       "      <td>Little Egret</td>\n",
       "      <td>112</td>\n",
       "      <td>foreground recording background recording egre...</td>\n",
       "      <td>foreground recording background recording egre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0           0  2 Jun 2023 ï¿½ The Javan myna shares some simi...   \n",
       "1           1  Click here for more information about the Red ...   \n",
       "2           2  The black-headed oriole ( Oriolus larvatus) is...   \n",
       "3           3  Search from thousands of royalty-free \"Javan M...   \n",
       "4           4   521 foreground recordings and 156 background ...   \n",
       "\n",
       "               species  text_length  \\\n",
       "0           Javan Myna          162   \n",
       "1  Collared Kingfisher          398   \n",
       "2   Black-naped Oriole          349   \n",
       "3           Javan Myna          177   \n",
       "4         Little Egret          112   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  jun javan myna share similarity common myna te...   \n",
       "1  click information red list category criterion ...   \n",
       "2  black headed oriole oriolus larvatus specie bi...   \n",
       "3  search thousand royalty free javan myna stock ...   \n",
       "4  foreground recording background recording egre...   \n",
       "\n",
       "                                             chunked  \n",
       "0  jun javan_myna share similarity common myna te...  \n",
       "1  click information red list category criterion ...  \n",
       "2  black_headed_oriole oriolus larvatus specie bi...  \n",
       "3  search thousand royalty free javan_myna stock ...  \n",
       "4  foreground recording background recording egre...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('230436M_cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb338f",
   "metadata": {},
   "source": [
    "#### **Feature Engineering**   \n",
    "There are different types of features that can be done, we will be using a mix of vectorizers as comparison. A base model will be trained to examine this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d0f332-a3c6-46bb-b6a5-07cff2348d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_text']\n",
    "Y=df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49988490-4989-460d-94b3-6457233df9aa",
   "metadata": {},
   "source": [
    "Setting test size and training size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b66dffb-111a-4b0c-82da-ad00be7f4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa89483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training: (488, 9684)\n",
      "test: (123, 9684)\n",
      "\n",
      "features: ['aa' 'aa sitesettingsid' 'ability' ... 'zimbabwe zambia' 'zoonosis'\n",
      " 'zoonosis singapore']\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "X_train_cv=cv.fit_transform(X_train)\n",
    "X_test_cv=cv.transform(X_test) #make sure X_test is TRANSFORM and not fit_transform\n",
    "\n",
    "#print dimensions and features \n",
    "print(f\"\"\"\n",
    "training: {X_train_cv.toarray().shape}\n",
    "test: {X_test_cv.toarray().shape}\n",
    "\n",
    "features: {cv.get_feature_names_out()}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae1e3afd-d4f8-46cc-a04c-112e8d4f2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Count Vectorizer.pkl', 'wb') as f1: \n",
    "    pickle.dump(cv, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324187cc-3be2-4ce5-8cb4-57c07f75619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training: (488, 9684)\n",
      "test: (123, 9684)\n",
      "\n",
      "features: ['aa' 'aa sitesettingsid' 'ability' ... 'zimbabwe zambia' 'zoonosis'\n",
      " 'zoonosis singapore']\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv=TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "X_train_tv=tv.fit_transform(X_train)\n",
    "X_test_tv=tv.transform(X_test) #make sure X_test is TRANSFORM and not fit_transform\n",
    "\n",
    "#print dimensions and features \n",
    "print(f\"\"\"\n",
    "training: {X_train_tv.toarray().shape}\n",
    "test: {X_test_tv.toarray().shape}\n",
    "\n",
    "features: {tv.get_feature_names_out()}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d891413",
   "metadata": {},
   "source": [
    "##### **Usage of A Base Model for testing**\n",
    "We will use a base model, Logistic Regression to decide which of the vectorizers or bag of words features can produce the most results. T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a9c8617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Count Vectorizer\n",
      "Accuracy: 0.9349593495934959 \n",
      "=================================================================================================\n",
      "\n",
      "Model: Tfidf Vectorizer\n",
      "Accuracy: 0.9349593495934959\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#train\n",
    "def vectorise_data(X_train_cv,X_test_cv):\n",
    "    lr=LogisticRegression(solver='lbfgs')\n",
    "    lr.fit(X_train_cv, y_train)\n",
    "    y_pred_cv=lr.predict(X_test_cv)\n",
    "    accuracy=accuracy_score(y_test, y_pred_cv)\n",
    "    return accuracy\n",
    "\n",
    "print(f'''\n",
    "Model: Count Vectorizer\n",
    "Accuracy: {vectorise_data(X_train_cv, X_test_cv)} \n",
    "=================================================================================================\n",
    "\n",
    "Model: Tfidf Vectorizer\n",
    "Accuracy: {vectorise_data(X_train_tv, X_test_cv)}\n",
    "''')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff2d7ae4",
   "metadata": {},
   "source": [
    "#### **Modelling**\n",
    "There will be a number of models tested.\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Naives Bayes\n",
    "3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b185da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing different models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#accuracy metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#list of models\n",
    "models=[\n",
    "    {'name': 'Logistic Regression', \n",
    "     'model': LogisticRegression(solver='lbfgs')}, \n",
    "    {'name': 'Naive Bayes (Multinomial)', \n",
    "     'model': MultinomialNB()}, \n",
    "    {'name': 'Naive Bayes (GaussianNB)', \n",
    "     'model': GaussianNB()}, \n",
    "]\n",
    "results=[]\n",
    "\n",
    "#printing confusion matrix    \n",
    "def conf_matrix(y_test, pred_test):    \n",
    "    # Creating a confusion matrix\n",
    "    con_mat = confusion_matrix(y_test, pred_test)\n",
    "    con_mat = pd.DataFrame(con_mat, range(4), range(4))\n",
    "    #Ploting the confusion matrix\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.set(font_scale=1.5) \n",
    "    sns.heatmap(con_mat, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a245f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Model Name: Logistic Regression\n",
      "    Accuracy: 0.93\n",
      "    Confusion Matrix: \n",
      "    ======================================================================================================\n",
      "    \n",
      "\n",
      "    Model Name: Naive Bayes (Multinomial)\n",
      "    Accuracy: 0.93\n",
      "    Confusion Matrix: \n",
      "    ======================================================================================================\n",
      "    \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modell \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_cv, y_train)\n\u001b[1;32m      6\u001b[0m     y_pred_cv\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X_test_cv)\n\u001b[1;32m      7\u001b[0m     accuracy\u001b[38;5;241m=\u001b[39maccuracy_score(y_test, y_pred_cv)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/naive_bayes.py:263\u001b[0m, in \u001b[0;36mGaussianNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[1;32m    264\u001b[0m     X, y, np\u001b[38;5;241m.\u001b[39munique(y), _refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight\n\u001b[1;32m    265\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/naive_bayes.py:423\u001b[0m, in \u001b[0;36mGaussianNB._partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    422\u001b[0m first_call \u001b[38;5;241m=\u001b[39m _check_partial_fit_first_call(\u001b[38;5;28mself\u001b[39m, classes)\n\u001b[0;32m--> 423\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39mfirst_call)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1302\u001b[0m     X,\n\u001b[1;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[1;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1316\u001b[0m )\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:971\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(array):\n\u001b[1;32m    970\u001b[0m     _ensure_no_complex_data(array)\n\u001b[0;32m--> 971\u001b[0m     array \u001b[38;5;241m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    972\u001b[0m         array,\n\u001b[1;32m    973\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m    974\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    975\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    976\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    977\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m    978\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    979\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    982\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    983\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D input, got input with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:595\u001b[0m, in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(sparse_container, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    594\u001b[0m     padded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m input_name \u001b[38;5;28;01mif\u001b[39;00m input_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse data was passed\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpadded_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but dense data is required. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.toarray()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to convert to a dense numpy array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m     )\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accept_sparse, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(accept_sparse) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "#run models and print classificaton report\n",
    "from sklearn.metrics import accuracy_score\n",
    "for modell in models:\n",
    "    model=modell['model']\n",
    "    model.fit(X_train_cv, y_train)\n",
    "    y_pred_cv=model.predict(X_test_cv)\n",
    "    accuracy=accuracy_score(y_test, y_pred_cv)\n",
    "    # confusionmatrix = conf_matrix(y_test, y_pred_cv)\n",
    "    print(f'''\n",
    "    Model Name: {modell['name']}\n",
    "    Accuracy: {accuracy:.2f}\n",
    "    Confusion Matrix: \n",
    "    ======================================================================================================\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1798baf9",
   "metadata": {},
   "source": [
    "### **Model 1: Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3788c115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Collared Kingfisher', 'Javan Myna', 'Little Egret', 'Javan Myna',\n",
       "       'Black-naped Oriole', 'Javan Myna', 'Collared Kingfisher',\n",
       "       'Javan Myna', 'Javan Myna', 'Black-naped Oriole',\n",
       "       'Black-naped Oriole', 'Black-naped Oriole', 'Collared Kingfisher',\n",
       "       'Black-naped Oriole', 'Javan Myna', 'Javan Myna',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Little Egret',\n",
       "       'Javan Myna', 'Little Egret', 'Little Egret', 'Little Egret',\n",
       "       'Javan Myna', 'Collared Kingfisher', 'Collared Kingfisher',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Collared Kingfisher',\n",
       "       'Black-naped Oriole', 'Collared Kingfisher', 'Javan Myna',\n",
       "       'Little Egret', 'Little Egret', 'Black-naped Oriole',\n",
       "       'Little Egret', 'Little Egret', 'Black-naped Oriole',\n",
       "       'Black-naped Oriole', 'Black-naped Oriole', 'Javan Myna',\n",
       "       'Little Egret', 'Little Egret', 'Black-naped Oriole',\n",
       "       'Black-naped Oriole', 'Little Egret', 'Little Egret', 'Javan Myna',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Black-naped Oriole',\n",
       "       'Javan Myna', 'Little Egret', 'Collared Kingfisher',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Collared Kingfisher',\n",
       "       'Collared Kingfisher', 'Javan Myna', 'Javan Myna', 'Javan Myna',\n",
       "       'Black-naped Oriole', 'Javan Myna', 'Javan Myna',\n",
       "       'Collared Kingfisher', 'Javan Myna', 'Collared Kingfisher',\n",
       "       'Little Egret', 'Little Egret', 'Collared Kingfisher',\n",
       "       'Little Egret', 'Black-naped Oriole', 'Little Egret',\n",
       "       'Black-naped Oriole', 'Little Egret', 'Little Egret',\n",
       "       'Collared Kingfisher', 'Collared Kingfisher', 'Javan Myna',\n",
       "       'Little Egret', 'Collared Kingfisher', 'Black-naped Oriole',\n",
       "       'Black-naped Oriole', 'Little Egret', 'Black-naped Oriole',\n",
       "       'Little Egret', 'Little Egret', 'Little Egret', 'Little Egret',\n",
       "       'Collared Kingfisher', 'Javan Myna', 'Javan Myna',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Javan Myna',\n",
       "       'Black-naped Oriole', 'Collared Kingfisher', 'Javan Myna',\n",
       "       'Little Egret', 'Black-naped Oriole', 'Javan Myna',\n",
       "       'Black-naped Oriole', 'Black-naped Oriole', 'Black-naped Oriole',\n",
       "       'Javan Myna', 'Black-naped Oriole', 'Black-naped Oriole',\n",
       "       'Javan Myna', 'Little Egret', 'Collared Kingfisher',\n",
       "       'Black-naped Oriole', 'Little Egret', 'Black-naped Oriole',\n",
       "       'Javan Myna', 'Black-naped Oriole', 'Black-naped Oriole',\n",
       "       'Collared Kingfisher', 'Javan Myna', 'Javan Myna',\n",
       "       'Collared Kingfisher', 'Black-naped Oriole', 'Black-naped Oriole',\n",
       "       'Black-naped Oriole'], dtype='<U19')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "lr=OneVsRestClassifier(LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "#train\n",
    "lr.fit(X_train_cv, y_train)\n",
    "\n",
    "#apply to test\n",
    "y_pred_cv=lr.predict(X_test_cv)\n",
    "y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d1040270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1357d8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m class_of_interest\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLittle Egret\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m class_id \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflatnonzero(label_binarizer\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m==\u001b[39m class_of_interest)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      7\u001b[0m display \u001b[38;5;241m=\u001b[39m RocCurveDisplay\u001b[38;5;241m.\u001b[39mfrom_predictions(\n\u001b[1;32m      8\u001b[0m     y_onehot_test[:, class_id],\n\u001b[0;32m----> 9\u001b[0m     y_pred_cv[:, class_id],\n\u001b[1;32m     10\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_of_interest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs the rest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarkorange\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     plot_chance_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m _ \u001b[38;5;241m=\u001b[39m display\u001b[38;5;241m.\u001b[39max_\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m     15\u001b[0m     xlabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalse Positive Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Positive Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne-vs-Rest ROC curves:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_of_interest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs (all)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "class_of_interest=\"Little Egret\"\n",
    "class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test[:, class_id],\n",
    "    y_pred_cv[:, class_id],\n",
    "    name=f\"{class_of_interest} vs the rest\",\n",
    "    color=\"darkorange\",\n",
    "    plot_chance_level=True,\n",
    ")\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=f\"One-vs-Rest ROC curves:\\{class_of_interest} vs (all)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "580075e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36,  0,  0,  3],\n",
       "       [ 1, 26,  0,  1],\n",
       "       [ 0,  0, 30,  2],\n",
       "       [ 1,  0,  0, 23]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred_cv)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084f4e9-d698-475d-a441-077d8ffa9c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "55908399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Black-naped Oriole       0.95      0.92      0.94        39\n",
      "Collared Kingfisher       1.00      0.93      0.96        28\n",
      "         Javan Myna       1.00      0.94      0.97        32\n",
      "       Little Egret       0.79      0.96      0.87        24\n",
      "\n",
      "           accuracy                           0.93       123\n",
      "          macro avg       0.94      0.94      0.93       123\n",
      "       weighted avg       0.94      0.93      0.94       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_cv, target_names=['Black-naped Oriole','Collared Kingfisher','Javan Myna','Little Egret']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e1a0f-021d-44cc-a2e7-06b0ab5bee99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c69dfd97",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b64a8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'Logistic Regression.pkl', 'wb') as f1: \n",
    "    pickle.dump(lr, f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12eff887",
   "metadata": {},
   "source": [
    "### **Model 2: Naives Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN DIFFERENCE IN CODE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb=MultinomialNB()\n",
    "\n",
    "#train\n",
    "nb.fit(X_train_cv, y_train)\n",
    "\n",
    "#move to X_test\n",
    "y_pred_cv=nb.predict(X_test_cv)\n",
    "# y_pred_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aad74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred_cv)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e53fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a confusion matrix \n",
    "def conf_matrix(y_test, pred_test):    \n",
    "    \n",
    "    # Creating a confusion matrix\n",
    "    con_mat = confusion_matrix(y_test, pred_test)\n",
    "    con_mat = pd.DataFrame(con_mat, range(4), range(4))\n",
    "   \n",
    "    #Ploting the confusion matrix\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.set(font_scale=1.5) \n",
    "    sns.heatmap(con_mat, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)\n",
    "    \n",
    "#Ploting the confusion matrix\n",
    "conf_matrix(y_test, y_pred_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f12a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_cv, target_names=['Black-naped Oriole','Collared Kingfisher','Javan Myna','Little Egret']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93e4a8",
   "metadata": {},
   "source": [
    "Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "supportvector=svm.LinearSVC()\n",
    "#train\n",
    "supportvector.fit(X_train_cv, y_train)\n",
    "\n",
    "#move to X_test\n",
    "y_pred_cv=supportvector.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242c3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, y_pred_cv)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "svm_results = classification_report(y_test, y_pred_cv, target_names=['Black-naped Oriole','Collared Kingfisher','Javan Myna','Little Egret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f186095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

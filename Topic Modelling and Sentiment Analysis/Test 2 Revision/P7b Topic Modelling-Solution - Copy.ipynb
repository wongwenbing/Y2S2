{
 "cells": [
  {
   "attachments": {
    "NYPLogo.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NYPLogo.png](attachment:NYPLogo.png)\n",
    "\n",
    "# Practical 7b: Topic Modelling\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Construct topic modelling models and evaluate using appropriate performance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "With the vast amount of unstructured text data, it is essential to find a method to organise the data in to meaningful groups or topics for actionable insights. Topic modelling is a technique to extract the hidden topics from the unstructured text. One of the popular topic modelling algorithm is Latent Dirichlet Allocation (LDA). With many implementations available in the internet, the challenge is not about implementing a topic model but how to extract good quality of topics. This depends on the quality of text preprocessing and the strategy of finding the optimal number of topics.,\n",
    "\n",
    "In this practical, we will be looking at how we can use Python gensim and nltk packages to implement a LDA topic model. \n",
    "\n",
    "Before you can use the various packages in Python, we need to make sure the relevant packages are installed and imported. \n",
    "\n",
    "> pip install gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Import libraries and download the packages\n",
    "\n",
    "```Python\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "import string\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "```\n",
    "*NOTE: Ignore the warning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp38-cp38-win_amd64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\wongw\\anaconda3\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\wongw\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Downloading gensim-4.3.3-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/24.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 6.8/24.0 MB 13.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.4/24.0 MB 13.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/24.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.0 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 4.2/42.2 MB 20.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 8.1/42.2 MB 20.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 13.1/42.2 MB 21.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 20.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 21.5/42.2 MB 20.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.4/42.2 MB 20.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 29.4/42.2 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 33.3/42.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  41.9/42.2 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.2/42.2 MB 18.9 MB/s eta 0:00:00\n",
      "Installing collected packages: scipy, gensim\n",
      "Successfully installed gensim-4.3.3 scipy-1.10.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wongw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wongw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwordnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m corpora\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# Enter code here\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "import string\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in source files from directory\n",
    "\n",
    "We need to extract the source files in to a data structure so that Python can process the data. The source files that we are using in this practical is extracted from sample BBC news with a total of 250 files from various categories. \n",
    "\n",
    "Make sure you have downloaded the data needed for the assignment. If not, please download the zipped file (**news.zip**) from Blackboard and unzip the contents. Ensure the news folder is in the same directory as your jupyter notebook.\n",
    "\n",
    "```Python\n",
    "#r is the raw string literals so that windows path slash won't create problem \n",
    "data_folder = Path(r'news')\n",
    "\n",
    "#read each file from the directory into an array and name it corpus\n",
    "corpus = []\n",
    "filenames = []\n",
    "\n",
    "for filename in data_folder.iterdir():\n",
    "   fp = open(str(filename), 'r', encoding='latin1')\n",
    "   corpus.append(fp.read())\n",
    "   #keep the filename for later use\n",
    "   filenames.append(filename.name)\n",
    "   fp.close()\n",
    "\n",
    "print(corpus.__len__())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "#r is the raw string literals so that windows path slash won't create problem \n",
    "data_folder = Path(r'news')\n",
    "\n",
    "#read each file from the directory into an array and name it corpus\n",
    "corpus = []\n",
    "filenames = []\n",
    "\n",
    "for filename in data_folder.iterdir():\n",
    "   fp = open(str(filename), 'r', encoding='latin1')\n",
    "   corpus.append(fp.read())\n",
    "   #keep the filename for later use\n",
    "   filenames.append(filename.name)\n",
    "   fp.close()\n",
    "\n",
    "print(corpus.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see ‘250’ being printed. It indicates content of 250 files has been stored in corpus.\n",
    "\n",
    "\n",
    "## Preprocessing\n",
    "As covered in previous lectures, there are many preprocessing steps. We will try three in this section. They are stop words removal; punctuation removal and lemmatization using WordNet.\n",
    "\n",
    "Setup the resources for the preprocessing steps\n",
    "```Python\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter codes here\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will proceed to clean up the content and keep it in the doc_clean variable.\n",
    "```Python\n",
    "def clean(doc):\n",
    "    punc_free = ''.join([ch for ch in doc.lower() if ch not in exclude])\n",
    "    stop_free = ' '.join([i for i in punc_free.split() if i not in stop]) \n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    #stemmed = ' '.join(stemmer.stem(word) for word in normalized.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in corpus]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter codes here\n",
    "def clean(doc):\n",
    "    punc_free = ''.join([ch for ch in doc.lower() if ch not in exclude])\n",
    "    stop_free = ' '.join([i for i in punc_free.split() if i not in stop]) \n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    #stemmed = ' '.join(stemmer.stem(word) for word in normalized.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare word representation\n",
    "Term frequency word representation is used in this practical and gensim package has implementation for it, which requires only 2 lines of codes.\n",
    "\n",
    "```Python\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "```\n",
    "The first line is making use Dictionary function of gensim corpora package to create a data structure keeping all the unique words. \n",
    "\n",
    "The second line is using the dictionary to create a doc to term matrix for each of the doc (or file) using bag of words approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter codes here\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LDA Model\n",
    "We are ready to create our first LDA model. As mentioned in the lecture, there is a need to specify the number of topics in LDA. The following code uses a variable topic_num to set a value 5 for the first model: \n",
    "\n",
    "```Python\n",
    "topic_num = 5\n",
    "word_num = 5\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics = topic_num, id2word = dictionary, passes=20)\n",
    "\n",
    "pprint(ldamodel.print_topics(num_topics=topic_num, num_words=word_num))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "topic_num = 5\n",
    "word_num = 5\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics = topic_num, id2word = dictionary, passes=20)\n",
    "\n",
    "pprint(ldamodel.print_topics(num_topics=topic_num, num_words=word_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that the results or the topics are not very meaningful, or it is hard to identify a category. \n",
    "\n",
    "The interpretation of the result is based on the topic id and its list of top keyword. For example, (0,\n",
    "  '0.011*\"said\" + 0.006*\"game\" + 0.005*\"would\" + 0.005*\"one\" + 0.004*\"people\"') means the top 5 keywords that contribute to Topic id 0 are ‘said’, ‘game’, ‘would’, ‘one’ and ‘people’ and the weight of ‘game’ is 0.006. The weights reflect how important a keyword is to that topic.\n",
    "\n",
    "*Note: For unsupervised learning, each time you run the step above, it will give you a different result. You can set the random_state parameter to fix the reproducibility. \n",
    "\n",
    "A lot of parameters can be tuned to optimize training. Find out more here: https://radimrehurek.com/gensim/models/ldamodel.html *\n",
    "\n",
    "\n",
    "## Topic Number\n",
    "\n",
    "As seen above, a topic number is needed to create the LDA topic model. However, how do we determine a suitable number to use? \n",
    "\n",
    "One option is to use the perplexity value. It is a statistical measure of how well a probability model predicts a sample. The value on its own is quite meaningless. Its benefit comes in when comparing different LDA model and model with the lower perplexity value is generally considered “better”.\n",
    "\n",
    "Add the following code:\n",
    "\n",
    "```Python\n",
    "# Compute Perplexity\n",
    "print('Perplexity: ', ldamodel.log_perplexity(doc_term_matrix))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "print('Perplexity: ', ldamodel.log_perplexity(doc_term_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Change the value of topic_num and check if there is any impact on the perplexity.\n",
    "\n",
    "**Do take note that by increasing topic_num to a large number may not help in understanding the categories (unless there is prior knowledge of a possible large value) and hence may sacrifice clarity.**\n",
    "\n",
    "By now, you would have noticed that some words (e.g., said, mr) kept appearing in the list of topics generated. It seems that these words should be considered as stop words and the generic stop words file cannot handle such domain specific words. As a result, let add in a few of the domain specific words to improve the results. This task works on the preprocessing step to assess if there is any impact by changing the stop words list and stemming.\n",
    "\n",
    "### Try the following\n",
    "\n",
    "1. Add in the following after the reading of stop words file\n",
    "```Python\n",
    "#addon to stop words\n",
    "domain_stop = [\"said\", \"mr\"]\n",
    "stop.update(domain_stop)\n",
    "```\n",
    "Run the program and see if there's any improvement.\n",
    "\n",
    "\n",
    "2. Add stemming to the preprocessing step. The following code adds in stemming for the content. Do take note that stemming should be added after the lemmatization under step 3. Remember to change the return statement to return stemmed.\n",
    "```Python\n",
    "stemmed = ' '.join(stemmer.stem(word) for word in normalized.split())\n",
    "```\n",
    "However, before stemmer can be called, you need to include the relevant packages. Add the following codes under step 3.\n",
    "```Python\n",
    "#stemming - English\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "domain_stop = [\"said\", \"mr\"]\n",
    "stop.update(domain_stop)\n",
    "\n",
    "# Enter codes here\n",
    "def clean(doc):\n",
    "    punc_free = ''.join([ch for ch in doc.lower() if ch not in exclude])\n",
    "    stop_free = ' '.join([i for i in punc_free.split() if i not in stop]) \n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    stemmed = ' '.join(stemmer.stem(word) for word in normalized.split())\n",
    "    return normalized\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Topic Details\n",
    "It is of interest to retrieve more details on the assigned topics. For example, total number of files assigned to the topics; the list of file names so that further processing on the identified files can be done. \n",
    "\n",
    "There are two parts to achieve the task.\n",
    "\n",
    "The first part is to find out the file name and its corresponding topic id(s) with probability. Recall that LDA is a probabilistic approach in modelling mixture of topics on a given content. As a result, LDA will assign the topic id(s) with its probability to indicate the content can potentially has more than one topic.\n",
    "\n",
    "The following code snippet will list out the file name and its corresponding topic ids with probability: \n",
    "\n",
    "```Python\n",
    "print('\\nFile name and its corresponding topic id with probability:')\n",
    "dic_topic_doc = {}\n",
    "for index, doc in enumerate(doc_clean):\n",
    "    #for doc in doc_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    \n",
    "    #get topic distribution of the ldamodel\n",
    "    t = ldamodel.get_document_topics(bow)\n",
    "    \n",
    "    #sort the probability value in descending order to extract the top contributing topic id\n",
    "    sorted_t = sorted(t, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #print only the filename \n",
    "    print(filenames[index],sorted_t)\n",
    "    \n",
    "    #get the top scoring item\n",
    "    top_item = sorted_t.pop(0)\n",
    "    \n",
    "    #create dictionary and keep key as topic id and filename and probability in tuple as value\n",
    "    dic_topic_doc.setdefault(top_item[0],[]).append((filenames[index],top_item[1]))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "print('\\nFile name and its corresponding topic id with probability:')\n",
    "dic_topic_doc = {}\n",
    "for index, doc in enumerate(doc_clean):\n",
    "    #for doc in doc_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    \n",
    "    #get topic distribution of the ldamodel\n",
    "    t = ldamodel.get_document_topics(bow)\n",
    "    \n",
    "    #sort the probability value in descending order to extract the top contributing topic id\n",
    "    sorted_t = sorted(t, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    #print only the filename \n",
    "    print(filenames[index],sorted_t)\n",
    "    \n",
    "    #get the top scoring item\n",
    "    top_item = sorted_t.pop(0)\n",
    "    \n",
    "    #create dictionary and keep key as topic id and filename and probability in tuple as value\n",
    "    dic_topic_doc.setdefault(top_item[0],[]).append((filenames[index],top_item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of the result is based on the set of topic id and probability. Some files only have one main topic assigned but other files have more than one. For example, 008.txt [(9, 0.82650626), (7, 0.1692603)] means that the file 008.txt is assigned with topic id 9 with probability of 0.82650626 and topic id 7 with probability of 0.1692603. In other words, topic id 9 is the main topic of 008.txt. \n",
    "\n",
    "The second part is to make use of the above information and transform it to extract the list of topic id, number of files (belong to this topic) and the list of file names with its probability (in descending order). \n",
    "\n",
    "The following code snippet prints out the identified topic id and its associated details, such as the number of files assigned to the topic and its corresponding probability value:\n",
    "\n",
    "```Python\n",
    "print('\\nTopic id, number of documents, list of documents with probability and represented topic words:')\n",
    "\n",
    "for key,value in dic_topic_doc.items():\n",
    "    sorted_value = sorted(value, key=lambda x: x[1], reverse=True)\n",
    "    print(key,len(value),sorted_value)\n",
    "    \n",
    "    #print the topic word and most represented doc\n",
    "    print(ldamodel.print_topic(key,word_num))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter code here\n",
    "print('\\nTopic id, number of documents, list of documents with probability and represented topic words:')\n",
    "\n",
    "for key,value in dic_topic_doc.items():\n",
    "    sorted_value = sorted(value, key=lambda x: x[1], reverse=True)\n",
    "    print(key,len(value),sorted_value)\n",
    "    \n",
    "    #print the topic word and most represented doc\n",
    "    print(ldamodel.print_topic(key,word_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of the result, based on the below output:\n",
    "\n",
    "0 13 [('206.txt', 0.99757373), ('112.txt', 0.99581325), ('221 .txt', 0.99573374) … <br />\n",
    "0.005*\"said\" + 0.005*\"network\" + 0.005*\"business\" + 0.004*\"uk\" + 0.004*\"could\"<br />\n",
    "1 28 [('111.txt', 0.9982385), ('245.txt', 0.9976861), ('127.txt', 0.9975066),….<br />\n",
    "0.007*\"people\" + 0.007*\"would\" + 0.006*\"said\" + 0.005*\"blair\" + 0.005*\"party\"\n",
    "\n",
    "means that topic id 0 has 13 files identified and 206.txt is assigned with the highest probability, followed by 112.txt and so on. Python starts its index with 0 but essentially, topic id 0 is the first topic identified.\n",
    "\n",
    "Similarly, the next is topic id 1 with 28 files identified and 111.txt is assigned with the highest probability, followed by 245.txt and so on.\n",
    "\n",
    "\n",
    "## Visualize Topics and Keywords\n",
    "\n",
    "Now, we are ready to visualize our LDA model.\n",
    "\n",
    "The following code uses the pyLDAvis tool to visualize the fit of your LDA model across topics and their top words.\n",
    "\n",
    "You will need to install the pyLDAvis package.\n",
    "> pip install pyLDAvis\n",
    "\n",
    "```Python\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the topics and keywords\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter codes here\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the topics and keywords\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
    "\n",
    "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant. A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart. \n",
    "\n",
    "If you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Load the **tripadvisor_hotel_reviews.csv** dataset into panda dataframe. Perform the following tasks:\n",
    "\n",
    "1. Prepare the data for topic modelling\n",
    "2. Train a LDA model\n",
    "3. Identify the topic\n",
    "4. Visualise the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your codes here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"tripadvisor_hotel_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the data for topic modelling\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "stop.update(domain_stop)\n",
    "\n",
    "# Enter codes here\n",
    "def clean(doc):\n",
    "    punc_free = ''.join([ch for ch in doc.lower() if ch not in exclude])\n",
    "    stop_free = ' '.join([i for i in punc_free.split() if i not in stop]) \n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    stemmed = ' '.join(stemmer.stem(word) for word in normalized.split())\n",
    "    return normalized\n",
    "\n",
    "df[\"preprocessed_review\"] = df['Review'].apply(lambda x : clean(x).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Train a LDA model\n",
    "\n",
    "corpus_text = df[\"preprocessed_review\"].values.tolist()\n",
    "corpus_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(corpus_text)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify the topic\n",
    "topic_num = 5\n",
    "word_num = 5\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics = topic_num, id2word = dictionary, passes=20)\n",
    "\n",
    "pprint(ldamodel.print_topics(num_topics=topic_num, num_words=word_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4. Visualise the topic\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the topics and keywords\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

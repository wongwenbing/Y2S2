{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries to pip install \n",
    "\n",
    "!pip install matplotlib\n",
    "!pip install spacy\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install pyLDAvis\n",
    "!pip install numpy==1.26.4\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pre-Processing data**\n",
    "## *Libraries to import*\n",
    "```Python\n",
    "from nltk.corpus import stopwords #stopwords\n",
    "from gensim.parsing.porter import PorterStemmer #stemming\n",
    "From nltk.stem import PorterStemmer #stemming\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #lemmatization\n",
    "\n",
    "porter_stemmer = PorterStemmer() #stemming\n",
    "lemma=WordNetLemmatizer() #lemmatization\n",
    "stopwordss=stopwords.words('english') #list of stopwords\n",
    "exclude=set(string.punctuation) #punctuations\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Cleaning*\n",
    "```Python\n",
    "def clean(doc):\n",
    "    punc_free = ''.join([ch for ch in doc.lower() if ch not in exclude]) #remove punctuations\n",
    "    stop_free = ' '.join([i for i in punc_free.split() if i not in stopwordss]) #remove stopwords\n",
    "    normalized = ' '.join(lemma.lemmatize(word) for word in stop_free.split()) #lemmatisation\n",
    "    stemmed = ' '.join(porter_stemmer.stem(word) for word in normalized.split()) #stemming\n",
    "    return normalized\n",
    "\n",
    "hotel_reviews[\"preprocessed_review\"] = hotel_reviews['Review'].apply(lambda x : clean(x).split()) #pandas dataframe\n",
    "doc_clean = [clean(doc).split() for doc in corpus] #list of documents given\n",
    "```\n",
    "Adding domain specific stopwords \n",
    "```Python\n",
    "#addon to stop words\n",
    "domain_stop = [\"said\", \"mr\"]\n",
    "stopwordss.update(domain_stop)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualising Text Data (EDA)**\n",
    "## *Frequency of Words: Frequency Distribution / WordCloud*\n",
    "```Python\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "reviews=hotel_reviews['Review'].tolist() #convert dataframe columns to list\n",
    "freq_dist=FreqDist(reviews_cleaned) #calculate frequency of words that should be a list\n",
    "freq_dist.plot(50, cumulative=False) #generate freq distribution plot \n",
    "cloud=WordCloud().generate_from_frequencies(freq_dist) #generate word cloud\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Given List, to calculate frequency of words: tokenize words before doing anything else*\n",
    "```Python\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "all_words = [word.lower() for sent in df.text for word in word_tokenize(sent)]\n",
    "all_words_frequency = FreqDist(all_words)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Distribution of Sentiments*\n",
    "```Python\n",
    "#group ratings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "pd.value_counts(hotel_reviews['Rating']).plot.bar(title=\"Rating Distribution\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Number of rows\")\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *POS and NER Tagging*\n",
    "- Need to tokenise the words first, before using POS-tagger in NLTK library for word tags\n",
    "- ** tokenize then pos tagging \n",
    "```Python\n",
    "def tagPOS(text):\n",
    "       wordsList = nltk.word_tokenize(text)  # Word tokenizers is used to find the words \n",
    "    tagged = nltk.pos_tag(wordsList)      #  Using a Tagger. Which is part-of-speech tagger or POS-tagger.  \n",
    "    return tagged\n",
    "df['POS_News'] = df['Text'].apply(lambda x: tagPOS(x))  #use lambda to apply tagPOS to each review\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Finding specific tag from tag text*\n",
    "**find the top N words based on the POS tag**  \n",
    "```Python\n",
    "def findtags(tag_prefix, tagged_text, n):\n",
    "    cfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text if tag.startswith(tag_prefix))\n",
    "    return dict((tag, cfd[tag].most_common(n)) for tag in cfd.conditions())\n",
    "```\n",
    "**find the top 5 adjective in the first news**\n",
    "```Python\n",
    "tagged_text = df['POS_News'][0]\n",
    "tagdict = findtags('JJ', tagged_text, 5)\n",
    "for tag in sorted(tagdict):\n",
    "    print(tag, tagdict[tag])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Named Entity Recognition (NER): identifies name entity*\n",
    "```Python\n",
    "from nltk import ne_chunk\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "res_chunk = ne_chunk(tagged_text) #NER chunking\n",
    "for x in str(res_chunk).split('\\n'):\n",
    "    if '/NN' in x:\n",
    "        print(x) #print tags with Noun NN\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sentiment Classification**\n",
    "\n",
    "## *Feature Extraction*\n",
    "- use top-N words feature\n",
    "### *Fetching words from corpus*\n",
    "```Python\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "all_words = [word.lower() for sent in df.text for word in word_tokenize(sent)\n",
    "# print first 10 words\n",
    "print (all_words[:10])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create frequency distribution of words: calculate occurences of each word in entire list of words* \n",
    "```Python\n",
    "from nltk import FreqDist\n",
    "all_words_frequency = FreqDist(all_words)\n",
    "print (all_words_frequency)\n",
    "# print 10 most frequently occurring words\n",
    "print (all_words_frequency.most_common(10))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## *Create Word Feature using 2000 most frequently occurring words*\n",
    "We take 2000 most frequently occurring words as our feature.\n",
    "```Python\n",
    "print (len(all_words_frequency)) \n",
    " \n",
    "# get 2000 frequently occuring words\n",
    "most_common_words = all_words_frequency.most_common(2000) #using nltk.FreqDist.most_common() to get the frequently occurring words\n",
    "\n",
    "# the most common words list's elements are in the form of tuple get \n",
    "# only the first element of each tuple of the word list\n",
    "word_features = [item[0] for item in most_common_words]\n",
    "print (word_features[:10])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Create Feature Set*\n",
    "- apply text preprocessing through loops for the reviews\n",
    "```Python\n",
    "df['text'] = df['text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "df['text'] = df['text'].apply(lambda x: clean(x))  \n",
    "df.head()\n",
    "```\n",
    "- create feature set to train classifier: checks if words in given document are present in word_features_list or not\n",
    "```Python\n",
    "def document_features(df, stemmed_tokens):\n",
    "    doc_features = []\n",
    "    for index, row in df.iterrows():\n",
    "        features = { }\n",
    "        for word in word_features:\n",
    "            # get term occurence: true if it's in the word_features, false if it's not\n",
    "            features[word] = (word in row[stemmed_tokens])\n",
    "        doc_features.append(features)\n",
    "    return doc_features\n",
    "feature_set = pd.DataFrame(document_features(df, 'text'), index = df.index)\n",
    "feature_set.head()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Training Classifier*\n",
    "*Creating Training and Test Set*\n",
    "```Python\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = feature_set\n",
    "y = df[df.columns[-1:]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print (y_train.sentiment.value_counts(normalize=True))\n",
    "\n",
    "#plot chart\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=y_train, x='sentiment')\n",
    "```\n",
    "\n",
    "*Training Classifier*\n",
    "```Python\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "#use decision tree in this case\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, classifier.predict(X_test)))\n",
    "\n",
    "# accuracy score\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy Score: \" + str(accuracy_score(y_test, y_pred)))\n",
    "```\n",
    "*Function a confusion matrix*\n",
    "```Python\n",
    "def conf_matrix(y_test, pred_test):    \n",
    "    # Creating a confusion matrix\n",
    "    con_mat = confusion_matrix(y_test, pred_test)\n",
    "    con_mat = pd.DataFrame(con_mat, range(2), range(2))\n",
    "    #Ploting the confusion matrix\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.set(font_scale=1.5) \n",
    "    sns.heatmap(con_mat, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)\n",
    "    \n",
    "#Implementing the confusion matrix\n",
    "conf_matrix(y_test, y_pred)\n",
    "```\n",
    "*Testing classifier with custom reviews*\n",
    "```Python\n",
    "# Negative review correctly classified as negative \n",
    "# Positive review is classified as negative\n",
    "data = {'custom_review': ['I hated the film. It was a disaster. Poor direction, bad acting.', \n",
    "                          'It was a wonderful and amazing movie. I loved it. Best direction, good acting.']}\n",
    "\n",
    "df_test = pd.DataFrame (data, columns = ['custom_review'])\n",
    "df_test['custom_review'] = df_test['custom_review'].apply(lambda x: word_tokenize(x.lower()))\n",
    "df_test['custom_review'] = df_test['custom_review'].apply(lambda x: clean(x))\n",
    "\n",
    "test_features = pd.DataFrame(document_features(df_test, 'custom_review'), index = df_test.index)\n",
    "print (classifier.predict(test_features))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Bag of Words using TF-IDF Feature*\n",
    "- create dictionary of unique words and calculate term weights for text feature.  \n",
    "*Creating Bag of Words features*\n",
    "```Python\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "# Build the dictionary\n",
    "mydict = corpora.Dictionary(df['text'])\n",
    "vocab_len = len(mydict)\n",
    "def get_bow_features(df, stemmed_tokens): #create term frequency features\n",
    "    test_features = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Converting the tokens into the format that the model requires\n",
    "        features = gensim.matutils.corpus2csc([mydict.doc2bow(row[stemmed_tokens])],num_terms=vocab_len).toarray()[:,0]\n",
    "        test_features.append(features)\n",
    "    return test_features\n",
    "\n",
    "header = \",\".join(str(mydict[ele]) for ele in range(vocab_len))\n",
    "\n",
    "bow_features = pd.DataFrame(get_bow_features(df, 'text'), columns=header.split(','), index = df.index)\n",
    "bow_features.head()\n",
    "\n",
    "#CREATE TERM WEIGHTS WITH TF-IDF\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# Build the dictionary\n",
    "mydict = corpora.Dictionary(df['text'])\n",
    "vocab_len = len(mydict)\n",
    "corpus = [mydict.doc2bow(line) for line in df['text']]\n",
    "tfidf_model = TfidfModel(corpus)\n",
    "\n",
    "def get_tfidf_features(df, stemmed_tokens):\n",
    "    test_features_tfidf = []\n",
    "    for index, row in df.iterrows():\n",
    "        doc = mydict.doc2bow(row[stemmed_tokens])\n",
    "        # Converting the tokens into the formet that the model requires\n",
    "        features = gensim.matutils.corpus2csc([tfidf_model[doc]], num_terms=vocab_len).toarray()[:,0]\n",
    "        test_features_tfidf.append(features)\n",
    "    return test_features_tfidf\n",
    "\n",
    "header = \",\".join(str(mydict[ele]) for ele in range(vocab_len))\n",
    "\n",
    "tfidf_features = pd.DataFrame(get_tfidf_features(df, 'text'),                            \n",
    "                            columns=header.split(','), index = df.index)\n",
    "tfidf_features.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Training Classifier + Accuracy calculation with TFIDF Feature Set*\n",
    "```Python\n",
    "X = tfidf_features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#using decision tree\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "# classification report\n",
    "print(classification_report(y_test, classifier.predict(X_test)))\n",
    "# accuracy score\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy Score: \" + str(accuracy_score(y_test, y_pred)))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Classifiers*\n",
    "**Decision Tree** \n",
    "```Python \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**Logistic Regression**\n",
    "```Python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(solver='lbfgs')\n",
    "\n",
    "```\n",
    "**Naive Bayes**\n",
    "```Python\n",
    "from sklearn.naive_bayes import GaussianNB #Gaussian Naive Bayes \n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Checking importance of features among entire features in feature set*\n",
    "```Python\n",
    "#Find out the most important features from the classification model\n",
    "importances = list(classifier.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 10)) for feature, importance in zip(tfidf_features.columns, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "top_i = 0\n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:10} Importance: {}'.format(*pair))\n",
    "    if top_i == 20:\n",
    "        break\n",
    "    top_i += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Topic Modelling**\n",
    "## *Import Libraries*\n",
    "```Python\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import gensim #for gensim LDA model\n",
    "from gensim import corpora\n",
    "import string\n",
    "from pathlib import Path\n",
    "```\n",
    "<<!Pre-Processing Here>>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Preparing word representation*\n",
    "- use gensim library to do term frequency word representation\n",
    "```Python\n",
    "dictionary = corpora.Dictionary(doc_clean) #use gensium corpora to create data structure keeping all unique words\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean] #use dictionary to create doc-term matrix for each of doc / file using bag of words approach\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Creating LDA model*\n",
    "- uses gensim lda models to set value of 5 for the first model to specify the number of topics for LDA\n",
    "```Python\n",
    "topic_num = 5 #no. Of topics is 5\n",
    "word_num = 5 # no. of words in topics is 5 \n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ldamodel = Lda(doc_term_matrix, num_topics = topic_num, id2word = dictionary, passes=20)\n",
    "\n",
    "pprint(ldamodel.print_topics(num_topics=topic_num, num_words=word_num))\n",
    "# Compute Perplexity\n",
    "print('Perplexity: ', ldamodel.log_perplexity(doc_term_matrix)) #need to write perplexity, important for practical test \n",
    "```\n",
    "\n",
    "Some pointers: \n",
    "- the results and topics are often difficult to identify a category and may not be meaningful\n",
    "- how do you determine a suitable number to use?\n",
    "    - use perplexity value - statistical measure of how well probability model predicts sample. benefit comes when comparing different LDA models and model with lower - perplexity value is considered better, \n",
    "    - Perplexity value is controlled by topic num and word num, What is a good enough perplexity value? (rmb to plot, ) \n",
    "- **increasing topic_num** to a large # **MAY NOT HELP** in understanding categories (unless prior knoweledge of possible large value), thus sacrificing clarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## *Retrieving topic details*\n",
    "- Part 1: find out file name and corresponding topic ids with probability. Given that LDA is probability in modelling mixture of topics on given content, LDA assign topic ids with probability to indicate content can potentially has more than topic. FILES TO TOPIC.\n",
    "```Python\n",
    "print('\\nFile name and its corresponding topic id with probability:')\n",
    "dic_topic_doc = {}\n",
    "for index, doc in enumerate(doc_clean):\n",
    "    #for doc in doc_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    #get topic distribution of the ldamodel\n",
    "    t = ldamodel.get_document_topics(bow)\n",
    "    #sort the probability value in descending order to extract the top contributing topic id\n",
    "    sorted_t = sorted(t, key=lambda x: x[1], reverse=True)\n",
    "    #print only the filename \n",
    "    print(filenames[index],sorted_t)\n",
    "    #get the top scoring item\n",
    "    top_item = sorted_t.pop(0)\n",
    "    #create dictionary and keep key as topic id and filename and probability in tuple as value\n",
    "dic_topic_doc.setdefault(top_item[0],[]).append((filenames[index],top_item[1]))\n",
    "```\n",
    "\n",
    "- Part 2: Making use of the above information, and transform to extract list of topic id, number of files (belong to topic) and list of file names with probability. TOPICS TO FILES. (both works)\n",
    "```Python \n",
    "#print out identified topic id and associated\n",
    "print('\\nTopic id, number of documents, list of documents with probability and represented topic words:')\n",
    "\n",
    "for key,value in dic_topic_doc.items():\n",
    "    sorted_value = sorted(value, key=lambda x: x[1], reverse=True)\n",
    "    print(key,len(value),sorted_value)\n",
    "    #print the topic word and most represented doc\n",
    "    print(ldamodel.print_topic(key,word_num))\n",
    "```\n",
    "The interpretation of the result, based on the below output: \n",
    "> 0 13 [('206.txt', 0.99757373), ('112.txt', 0.99581325), ('221 .txt', 0.99573374) … \n",
    "> 0.005*\"said\" + 0.005*\"network\" + 0.005*\"business\" + 0.004*\"uk\" + 0.004*\"could\"\n",
    "means that topic id 0 has 13 files identified and 206.txt is assigned with the highest probability, followed by 112.txt and so on. Python starts its index with 0 but essentially, topic id 0 is the first topic identified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Visualize Topics and Keywords*\n",
    "- using pyLDAvis to visualise fit of model across topics and top words\n",
    "- Plotted at PCA (Principal Component Analysis) with doc-term matrix. PCA ensures dimension reduction. \n",
    "- The overlapping topics, would imply that there are similar words in overlaps. Which is not distinctive topics, hence choose a good alpha, beta. To improve this, increase the topic numbers! To have more topic numbers, to have higher cluster bubbles.\n",
    "    - Challenge: the more the # of topics may be more distinct, but there are some issues with similar words too! Issues with more topic clusters in LDA: \n",
    "- Perplexity lower the better but until what value? \n",
    "\n",
    "> pip install pyLDAvis\n",
    "\n",
    "```Python\n",
    "# plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the topics and keywords\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, doc_term_matrix, dictionary)\n",
    "vis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Plotting Perplexity against # of Topics* \n",
    "```Python\n",
    "# setting ranges\n",
    "topic_range = range(2, 21)\n",
    "perplexity_values = []\n",
    "dictionary = corpora.Dictionary(corpus_text) #use gensium corpora to create data structure keeping all unique words\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus_text] #use dictionary to create doc-term matrix for each of doc / file using bag of words approach    \n",
    "\n",
    "#Train models and calculate perplexity\n",
    "for num_topics in topic_range:\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics = topic_num, id2word = dictionary, passes=20)\n",
    "    perplexity = ldamodel.log_perplexity(doc_term_matrix)\n",
    "    perplexity_values.append(perplexity)\n",
    "    print(f'num_topics: {num_topics}, perplexity: {perplexity}')\n",
    "\n",
    "# Plotting perplexity\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(topic_range, perplexity_values, marker='o')\n",
    "plt.title('Perplexity vs Number of Topics')\n",
    "plt.xlabel('Number of Topics')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
